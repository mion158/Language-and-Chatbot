{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "word2vec = spacy.load(\"en_core_web_sm\")\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stop_words = set(stopwords.words())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mop1ACE0Eb0",
        "outputId": "2cb30a29-eeb9-43e5-b03c-e32568b2f8ce"
      },
      "id": "1Mop1ACE0Eb0",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exit_commands = (\"quit\", \"goodbye\", \"bye\" \"exit\", \"no\")\n",
        "response_a = \"The {} has a gluten-free option, but it is not vegan\"\n",
        "response_b = \"We have a selection of sides to go along with the {}, including mashed potatoes and steamed vegatables.\"\n",
        "response_c = \"{} includes habanero, so it is a bit spicy!\"\n",
        "blank_spot = \"food\"\n",
        "responses = [response_a, response_b, response_c]"
      ],
      "metadata": {
        "id": "mxpU39Fs1ElE"
      },
      "id": "mxpU39Fs1ElE",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(input_sentence):\n",
        "    input_sentence = input_sentence.lower()\n",
        "    input_sentence = re.sub(r'[^\\w\\s]','',input_sentence)\n",
        "    tokens = word_tokenize(input_sentence)\n",
        "    input_sentence = [i for i in tokens if not i in stop_words]\n",
        "    return(input_sentence)\n",
        "\n",
        "def compare_overlap(user_message, possible_response):\n",
        "    similar_words = 0\n",
        "    for token in user_message:\n",
        "        if token in possible_response:\n",
        "              similar_words += 1\n",
        "    return similar_words\n",
        "  \n",
        "def extract_nouns(tagged_message):\n",
        "    message_nouns = list()\n",
        "    for token in tagged_message:\n",
        "        if token[1].startswith(\"N\"):\n",
        "            message_nouns.append(token[0])\n",
        "    return message_nouns\n",
        "\n",
        "def compute_similarity(tokens, category):\n",
        "    output_list = list()\n",
        "    for token in tokens:\n",
        "        output_list.append([token.text, category.text, token.similarity(category)])\n",
        "    return output_list"
      ],
      "metadata": {
        "id": "GShEqKn91HfU"
      },
      "id": "GShEqKn91HfU",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "  \n",
        "  #exit method:\n",
        "  def make_exit(self, user_message):\n",
        "    for exit_command in exit_commands:\n",
        "      if exit_command in user_message:\n",
        "        print(\"Bye\")\n",
        "        return True\n",
        "    \n",
        "    return False \n",
        "\n",
        "  #chat method\n",
        "  def chat(self):\n",
        "    user_message = input(\"How can I help?\\n\")\n",
        "    while not self.make_exit(user_message):\n",
        "      user_message = self.respond(user_message)\n",
        "    \n",
        "  #method to match intent below:\n",
        "  def find_intent_match(self, responses, user_message):\n",
        "    bow_user_message = Counter(preprocess(user_message))\n",
        "    processed_responses = [Counter(preprocess(response)) for response in responses]\n",
        "    \n",
        "    similarity_list = [compare_overlap(response, bow_user_message) for response in processed_responses]\n",
        "    response_index = similarity_list.index(max(similarity_list))\n",
        "    return responses[response_index]\n",
        "\n",
        "\n",
        "  #method to find entities\n",
        "  def find_entities(self, user_message):\n",
        "    tagged_user_message = pos_tag(preprocess(user_message))\n",
        "    message_nouns = extract_nouns(tagged_user_message)\n",
        "\n",
        "    tokens = word2vec(\"\".join(message_nouns))\n",
        "    category = word2vec(blank_spot)\n",
        "    word2vec_result = compute_similarity(tokens, category)\n",
        "\n",
        "    word2vec_result.sort(key=lambda x: x[2])\n",
        "    if len(word2vec_result) < 1:\n",
        "      return blank_spot\n",
        "    else:\n",
        "      return word2vec_result[-1][0]\n",
        "\n",
        "\n",
        "\n",
        "  #method to respond to intent\n",
        "  def respond(self, user_message):\n",
        "    best_response = self.find_intent_match(responses,user_message)\n",
        "    entity = self.find_entities(user_message)\n",
        "    print(best_response.format(entity))\n",
        "\n",
        "    more_questions_message = input('Do you have other questions?\\n')\n",
        "    return more_questions_message  "
      ],
      "metadata": {
        "id": "qfmtn6V11Hh4"
      },
      "id": "qfmtn6V11Hh4",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize ChatBot instance:\n",
        "chatbot = ChatBot()\n",
        "chatbot.chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkGcJgxe1HkI",
        "outputId": "0244c380-20e4-46c9-8c35-9566becd2a10"
      },
      "id": "IkGcJgxe1HkI",
      "execution_count": 55,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I help?\n",
            "is habanero pepper good?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "habaneropepper includes habanero, so it is a bit spicy!\n",
            "Do you have other questions?\n",
            "no\n",
            "Bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdXP_dMt1HmE"
      },
      "id": "cdXP_dMt1HmE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "riazum5o1HoH"
      },
      "id": "riazum5o1HoH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4KtxiIAM1HqD"
      },
      "id": "4KtxiIAM1HqD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ChkPT251HsP"
      },
      "id": "2ChkPT251HsP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTo2YsmI1Hvo"
      },
      "id": "dTo2YsmI1Hvo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
